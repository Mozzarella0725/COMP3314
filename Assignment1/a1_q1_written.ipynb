{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMP3314 Assignment1-Q1: Written Questions (50 Points)\n",
    "\n",
    "Solve the following questions by hand. No need to implement any code. \n",
    "\n",
    "You should use Markdown to write texts and LaTex to write math equations. See this [documentation](https://jupyter-notebook.readthedocs.io/en/stable/examples/Notebook/Working%20With%20Markdown%20Cells.html) on how to use Markdown and LaTex in Jupyter Notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1-1: Perceptron Basics (5 points)\n",
    "\n",
    "### Question\n",
    "\n",
    "Consider a Perceptron with 3 inputs and 1 output (1 or -1). Let the weights of the Perceptron be $w_1 = -1$, $w_2 = 0.5$, and $w_3 = 1$, and let the bias be $w_0 = -1.5$. Calculate the output of the following inputs: $(0, 0, 0), (1, 0, 0), (0, 1, 1), (1, 1, 1), (1,2, -1)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1-2: Boolean Operators (5 points)\n",
    "\n",
    "### Question\n",
    "\n",
    "In this question, we will review boolean operations. Assume the inputs 2-dimensional binary values of 0 (false) and 1 (true). For example, input $(x_1, x_2)$ can only have the following values: $(0, 0), (0, 1), (1, 0), (1, 1)$. Complete the following truth tables for `NOT`, `AND`, `OR`, `NAND`, `NOR`, `XOR`. \n",
    "\n",
    "You will use these truth tables in Q2, where you will implement perceptrons to compute these boolean operations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer\n",
    "\n",
    "`NOT`: (example table)\n",
    "| $x_1$ | output |\n",
    "| ----- | ------ |\n",
    "| 0     | 1      |\n",
    "| 1     | 0      |\n",
    "\n",
    "`AND`:\n",
    "| $x_1$ | $x_2$ | output |\n",
    "| ----- | ----- | ------ |\n",
    "| 0     | 0     |        |\n",
    "| 0     | 1     |        |\n",
    "| 1     | 0     |        |\n",
    "| 1     | 1     |        |\n",
    "\n",
    "`OR`:\n",
    "| $x_1$ | $x_2$ | output |\n",
    "| ----- | ----- | ------ |\n",
    "| 0     | 0     |        |\n",
    "| 0     | 1     |        |\n",
    "| 1     | 0     |        |\n",
    "| 1     | 1     |        |\n",
    "\n",
    "`NAND`:\n",
    "| $x_1$ | $x_2$  | output |\n",
    "| ----- | ------ | ------ |\n",
    "| 0     | 0      |        |\n",
    "| 0     | 1      |        |\n",
    "| 1     | 0      |        |\n",
    "| 1     | 1      |        |\n",
    "\n",
    "`NOR`:\n",
    "| $x_1$ | $x_2$ | output |\n",
    "| ----- | ----- | ------ |\n",
    "| 0     | 0     |        |\n",
    "| 0     | 1     |        |\n",
    "| 1     | 0     |        |\n",
    "| 1     | 1     |        |\n",
    "\n",
    "`XOR`:\n",
    "| $x_1$ | $x_2$ | output |\n",
    "| ----- | ----- | ------ |\n",
    "| 0     | 0     |        |\n",
    "| 0     | 1     |        |\n",
    "| 1     | 0     |        |\n",
    "| 1     | 1     |        |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1-3: Parity Check (10 points)\n",
    "\n",
    "### Question\n",
    "\n",
    "The parity problem returns 1 if the number of inputs that are 1 is even, and 0 otherwise. Can a perceptron learn this problem for 4 inputs? Please provide a detailed explanation. If not learnable for 4 inputs, is there any number of inputs that is learnable for a perceptron?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1-4: Perceptron (30 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question\n",
    "Consider the perceptron algorithm and the following sequence of samples:\n",
    "\n",
    "$ x^{(1)} = (-1, 3), \\; x^{(2)} = (2, -2), \\; x^{(3)} = (-5, -3) $\n",
    "\n",
    "$ y^{(1)} = -1, \\; y^{(2)} = 1, \\; y^{(3)} = 1 $\n",
    "\n",
    "\n",
    "- We initialize all weights with 1 and all bias with 0.\n",
    "- We set the learning rate $\\eta = 1$.\n",
    "- We use $w_0$ to denote the bias term, and $w_1, w_2$ to denote the weights.\n",
    "- Reminder of the update rule: $w_j:=w_j+\\Delta w_j$, where $\\Delta w_j=\\eta\\left(y^{(i)}-\\hat{y}^{(i)}\\right) x_j^{(i)}$ if  $j>0 $. $\\Delta w_0=\\eta\\left(y^{(i)}-\\hat{y}^{(i)}\\right)$\n",
    "\n",
    "- Reminder of the decision function: $\\phi(z) = 1$ if $z >= 0$, and $\\phi(z) = -1$ otherwise.\n",
    "\n",
    "Answer the following three questions, and you need to provide the necessary formulas, steps, and analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q1-4-1  (5 points)\n",
    "Is this dataset linearly separable? \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q1-4-2  (5 points)\n",
    "After initializing the parameters and without training, what is the prediction accuracy on the training set? Write down your calculation steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q1-4-3 (20 points)\n",
    "After training for one epoch (seeing each training sample exactly once sequentially), what is the prediction accuracy on the training set? Write down your calculation steps."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "vscode": {
   "interpreter": {
    "hash": "d17123b7a852ae6f995cf965aca53bbdb6bda840a01f47f622e12eaae1166d96"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
