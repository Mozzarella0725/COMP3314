{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rXspZ7EHNDuc"
      },
      "source": [
        "# COMP3314 Assignment1-Q1: Written Questions (50 Points)\n",
        "\n",
        "Solve the following questions by hand. No need to implement any code.\n",
        "\n",
        "You should use Markdown to write texts and LaTex to write math equations. See this [documentation](https://jupyter-notebook.readthedocs.io/en/stable/examples/Notebook/Working%20With%20Markdown%20Cells.html) on how to use Markdown and LaTex in Jupyter Notebook."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gC7p1NzINDud"
      },
      "source": [
        "## Q1-1: Perceptron Basics (5 points)\n",
        "\n",
        "### Question\n",
        "\n",
        "Consider a Perceptron with 3 inputs and 1 output (1 or -1). Let the weights of the Perceptron be $w_1 = -1$, $w_2 = 0.5$, and $w_3 = 1$, and let the bias be $w_0 = -1.5$. Calculate the output of the following inputs: $(0, 0, 0), (1, 0, 0), (0, 1, 1), (1, 1, 1), (1,2, -1)$."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Answer\n",
        "To calculate the output of the Perceptron, we can use the following formula:\n",
        "$$ \\text{output} = \\text{sign}(w_0 + w_1 \\cdot x_1 + w_2 \\cdot x_2 + w_3 \\cdot x_3) $$\n",
        "where the sign function outputs 1 if the result is greater than 0, and -1 otherwise.\n",
        "\n",
        "Given the weights:\n",
        "$$ w_1 = -1$$ $$ w_2=0.5$$ $$ w_3=1$$ $$ w_0=-1.5 $$\n",
        "We can calculate the output for each input:\n",
        "1. For input $(0,0,0)$:\n",
        "$$  \\text{output} = \\text{sign}(-1.5 + (-1) \\cdot 0 + 0.5 \\cdot 0 + 1 \\cdot 0) = \\text{sign}(-1.5) = -1 $$\n",
        "2. For input $(1,0,0)$:\n",
        "$$ \\text{output} = \\text{sign}(-1.5 + (-1) \\cdot 1 + 0.5 \\cdot 0 + 1 \\cdot 0) = \\text{sign}(-2.5) = -1 $$\n",
        "3. For input $(0,1,1)$:\n",
        "$$  \\text{output} = \\text{sign}(-1.5 + (-1) \\cdot 0 + 0.5 \\cdot 1 + 1 \\cdot 1) = \\text{sign}(0) = 1 $$\n",
        "4. For input $(1,1,1)$:\n",
        "$$ \\text{output} = \\text{sign}(-1.5 + (-1) \\cdot 1 + 0.5 \\cdot 1 + 1 \\cdot 1) = \\text{sign}(-1) = -1 $$\n",
        "5. For input $(1,2,-1)$:\n",
        "$$ \\text{output} = \\text{sign}(-1.5 + (-1) \\cdot 1 + 0.5 \\cdot 2 + 1 \\cdot (-1)) = \\text{sign}(-2.5) = -1 $$\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Dr_YS_LJRY8_"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qHL8x3RPNDud"
      },
      "source": [
        "## Q1-2: Boolean Operators (5 points)\n",
        "\n",
        "### Question\n",
        "\n",
        "In this question, we will review boolean operations. Assume the inputs 2-dimensional binary values of 0 (false) and 1 (true). For example, input $(x_1, x_2)$ can only have the following values: $(0, 0), (0, 1), (1, 0), (1, 1)$. Complete the following truth tables for `NOT`, `AND`, `OR`, `NAND`, `NOR`, `XOR`.\n",
        "\n",
        "You will use these truth tables in Q2, where you will implement perceptrons to compute these boolean operations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z6aCtPHnNDue"
      },
      "source": [
        "### Answer\n",
        "\n",
        "`NOT`: (example table)\n",
        "\n",
        "| $x_1$ | output |\n",
        "| ----- | ------ |\n",
        "| 0     | 1      |\n",
        "| 1     | 0      |\n",
        "\n",
        "`AND`:\n",
        "\n",
        "| $x_1$ | $x_2$ | output |\n",
        "| ----- | ----- | ------ |\n",
        "| 0     | 0     |  0      |\n",
        "| 0     | 1     |   0     |\n",
        "| 1     | 0     |   0     |\n",
        "| 1     | 1     |    1    |\n",
        "\n",
        "`OR`:\n",
        "\n",
        "| $x_1$ | $x_2$ | output |\n",
        "| ----- | ----- | ------ |\n",
        "| 0     | 0     | 0       |\n",
        "| 0     | 1     |  1      |\n",
        "| 1     | 0     |   1     |\n",
        "| 1     | 1     |    1    |\n",
        "\n",
        "`NAND`:\n",
        "\n",
        "| $x_1$ | $x_2$  | output |\n",
        "| ----- | ------ | ------ |\n",
        "| 0     | 0      | 1       |\n",
        "| 0     | 1      |  1      |\n",
        "| 1     | 0      |   1     |\n",
        "| 1     | 1      |    0    |\n",
        "\n",
        "`NOR`:\n",
        "\n",
        "| $x_1$ | $x_2$ | output |\n",
        "| ----- | ----- | ------ |\n",
        "| 0     | 0     | 1       |\n",
        "| 0     | 1     |  0      |\n",
        "| 1     | 0     |   0     |\n",
        "| 1     | 1     |    0    |\n",
        "\n",
        "`XOR`:\n",
        "\n",
        "| $x_1$ | $x_2$ | output |\n",
        "| ----- | ----- | ------ |\n",
        "| 0     | 0     | 0      |\n",
        "| 0     | 1     |  1      |\n",
        "| 1     | 0     |   1     |\n",
        "| 1     | 1     |    0    |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3F7iZwQwNDue"
      },
      "source": [
        "## Q1-3: Parity Check (10 points)\n",
        "\n",
        "### Question\n",
        "\n",
        "The parity problem returns 1 if the number of inputs that are 1 is even, and 0 otherwise. Can a perceptron learn this problem for 4 inputs? Please provide a detailed explanation. If not learnable for 4 inputs, is there any number of inputs that is learnable for a perceptron?"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Answer\n",
        "In the case of 4 inputs, we have 16 possible input combinations from $(0,0,0,0)$ to $(1,1,1,1)$.\n",
        "\n",
        "Input combinations resulting in an output of 1 (even parity) include: $(0,0,0,0), (0,1,1,0), (1,0,1,0), (1,1,0,0), (0,0,1,1), (0,1,0,1), (1,0,0,1), (1,1,1,1)$.\n",
        "Combinations resulting in an output of 0 (odd parity) include: $ (0,0,0,1), (0,0,1,0), (0,1,0,0), (1,0,0,0), (0,1,1,1), (1,0,1,1), (1,1,0,1), (1,1,1,0) $.\n",
        "\n",
        "In 4-dimensional space, the points with an output of 1 and the points with an output of 0 are mixed together, and no straight line (hyperplane) can completely separate them. This means that the perceptron cannot find a set of weights and biases that will separate the two types of points completely In 4-dimensional space.\n",
        "\n",
        "There are certain numbers of inputs that are learnable for a perceptron:\n",
        "\n",
        "**1 input**: A perceptron can learn a simple binary function, where it outputs 1 for input 1 and 0 for input 0. This is trivially linearly separable.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "RWQgmzI0VvqJ"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mr7oJQOENDue"
      },
      "source": [
        "## Q1-4: Perceptron (30 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZB8FXGqpNDue"
      },
      "source": [
        "### Question\n",
        "Consider the perceptron algorithm and the following sequence of samples:\n",
        "\n",
        "$ x^{(1)} = (-1, 3), \\; x^{(2)} = (2, -2), \\; x^{(3)} = (-5, -3) $\n",
        "\n",
        "$ y^{(1)} = -1, \\; y^{(2)} = 1, \\; y^{(3)} = 1 $\n",
        "\n",
        "\n",
        "- We initialize all weights with 1 and all bias with 0.\n",
        "- We set the learning rate $\\eta = 1$.\n",
        "- We use $w_0$ to denote the bias term, and $w_1, w_2$ to denote the weights.\n",
        "- Reminder of the update rule: $w_j:=w_j+\\Delta w_j$, where $\\Delta w_j=\\eta\\left(y^{(i)}-\\hat{y}^{(i)}\\right) x_j^{(i)}$ if  $j>0 $. $\\Delta w_0=\\eta\\left(y^{(i)}-\\hat{y}^{(i)}\\right)$\n",
        "\n",
        "- Reminder of the decision function: $\\phi(z) = 1$ if $z >= 0$, and $\\phi(z) = -1$ otherwise.\n",
        "\n",
        "Answer the following three questions, and you need to provide the necessary formulas, steps, and analysis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bGMUGcQtNDue"
      },
      "source": [
        "#### Q1-4-1  (5 points)\n",
        "Is this dataset linearly separable?\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Answer\n",
        "In the dataset, we have:\n",
        "1. Positive Class (1):$(2,-2)$,$(-5,-3)$\n",
        "2. Negative Class (-1):$(-1,3)$\n",
        "\n",
        "The Positive Class is located in the lower half of the coordicate space, while the Negetive Class is in the upper half.\n",
        "\n",
        "Introduce a separating line $y=0$, the Positive Class is below the line and the Negative Class is above the line. Thus, this dataset is linearly separable."
      ],
      "metadata": {
        "id": "GLZ9tp6Daovx"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BvTUDB5YNDue"
      },
      "source": [
        "#### Q1-4-2  (5 points)\n",
        "After initializing the parameters and without training, what is the prediction accuracy on the training set? Write down your calculation steps."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Answer\n",
        "**Prediction Steps**\n",
        "\n",
        "Compute the value $z$ using the deision function and apply the decide function:\n",
        "\n",
        "1. $ x^{(1)} = (-1, 3) $\n",
        "  $$ z = w_0 + w_1 x_1 + w_2 x_2 = 0 + 1(-1) + 1(3) = 2 \\\\\n",
        "  \\hat{y}^{(1)} = \\phi(2) = 1 \\\\\n",
        "  (\\text{Predicted: } 1, \\text{ Actual: } -1) $$\n",
        "2. $ x^{(2)} = (2, -2) $\n",
        "  $$ z = w_0 + w_1 x_1 + w_2 x_2 = 0 + 1(2) + 1(2) = 0 \\\\\n",
        "  hat{y}^{(1)} = \\phi(0) = 1 \\\\\n",
        "  (\\text{Predicted: } 1, \\text{ Actual: } 1) $$\n",
        "3. $ x^{(3)} = (-5, -3) $\n",
        "  $$ z = w_0 + w_1 x_1 + w_2 x_2 = 0 + 1(-5) + 1(-3) = -8 \\\\\n",
        "  \\hat{y}^{(3)} = \\phi(-8) = -1 \\\\\n",
        "  (\\text{Predicted: } -1, \\text{ Actual: } 1) $$\n",
        "\n",
        "**Summary of Predictions**\n",
        "- $\\hat{y}^{(1)} = 1$ (incorrect)\n",
        "- $\\hat{y}^{(2)} = 1$ (correct)\n",
        "- $\\hat{y}^{(3)} = -1$(incorrect)\n",
        "\n",
        "**Accuracy Calculation**\n",
        "\n",
        "$$ \\text{Accuracy} = \\frac{\\text{Number of Correct Predictions}}{\\text{Total Predictions}} = \\frac{1}{3} \\approx 0.33 $$ or **33.33%**.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "hmOTgzF2c4R8"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "amWHJynsNDue"
      },
      "source": [
        "#### Q1-4-3 (20 points)\n",
        "After training for one epoch (seeing each training sample exactly once sequentially), what is the prediction accuracy on the training set? Write down your calculation steps."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Answer\n",
        "\n",
        "**Training for one epoch**\n",
        "\n",
        "1. $ x^{(1)} = (-1, 3), y^{(1)} = -1 $\n",
        "- Calculate $z$:\n",
        "  $$ z = 0 + 1(-1) + 1(3) = 2 $$\n",
        "- Prediction:\n",
        "  $$ \\hat{y}^{(1)} = \\phi(2) = 1 $$\n",
        "- Update weights:\n",
        "  $$ \\Delta w_0 = -2, \\quad \\Delta w_1 = 2, \\quad \\Delta w_2 = -6 $$\n",
        "- Updated weights:\n",
        "  $$ w_0 = -2, \\quad w_1 = 3, \\quad w_2 = -5 $$\n",
        "\n",
        "2. $ x^{(2)} = (2, -2),  y^{(2)} = 1 $\n",
        "- Calculate $z$:\n",
        "  $$z = -2 + 3(2) - 5(-2) = 14 $$\n",
        "- Prediction:\n",
        "  $$ \\hat{y}^{(2)} = \\phi(14) = 1$$\n",
        "- No update since $y^{(2)} = \\hat{y}^{(2)} $.\n",
        "\n",
        "3. $ x^{(3)} = (-5, -3), y^{(3)} = 1 $\n",
        "- Calculate $z$:\n",
        "  $$ z = -2 + 3(-5) - 5(-3) = -2 $$\n",
        "- Prediction:\n",
        "  $$ \\hat{y}^{(3)} = \\phi(-2) = -1 $$\n",
        "- Update weights:\n",
        "  $$ \\Delta w_0 = 2, \\quad \\Delta w_1 = -10, \\quad \\Delta w_2 = -6 $$\n",
        "- Updated weights:\n",
        "  $$ w_0 = 0, \\quad w_1 = -7, \\quad w_2 = -11 $$\n",
        "\n",
        "**Final Weights After One Epoch**\n",
        "- $ w_0 = 0 $\n",
        "- $ w_1 = -7 $\n",
        "- $ w_2 = -11 $\n",
        "\n",
        "**Recalculate Predictions**\n",
        "\n",
        "1. $ x^{(1)} = (-1, 3) $\n",
        "   $$ z = 0 + (-7)(-1) + (-11)(3) = -26 \\quad \\hat{y}^{(1)} = -1 $$\n",
        "\n",
        "2. $ x^{(2)} = (2, -2) $\n",
        "   $$ z = 0 + (-7)(2) + (-11)(-2) = 8 \\quad \\hat{y}^{(2)} = 1 $$\n",
        "\n",
        "3. $ x^{(3)} = (-5, -3) $\n",
        "   $$ z = 0 + (-7)(-5) + (-11)(-3) = 68 \\quad \\hat{y}^{(3)} = 1 $$\n",
        "\n",
        "**Summary of Final Predictions**\n",
        "- $ \\hat{y}^{(1)} = -1 $ (correct)\n",
        "- $ \\hat{y}^{(2)} = 1 $ (correct)\n",
        "- $ \\hat{y}^{(3)} = 1 $ (incorrect)\n",
        "\n",
        "**Accuracy Calculation**\n",
        "$$ \\text{Accuracy} = \\frac{\\text{Number of Correct Predictions}}{\\text{Total Predictions}} = \\frac{2}{3} \\approx 0.67 $$ or **66.67%**."
      ],
      "metadata": {
        "id": "kX18oay0f9Tw"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    },
    "vscode": {
      "interpreter": {
        "hash": "d17123b7a852ae6f995cf965aca53bbdb6bda840a01f47f622e12eaae1166d96"
      }
    },
    "colab": {
      "provenance": [],
      "toc_visible": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}